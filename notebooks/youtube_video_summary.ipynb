{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Youtube Video Summary\n",
    "\n",
    "*Uses the YouTube API to get the transcript of a video and then uses the Google Generative AI to summarize the video transcript.*"
   ],
   "id": "4ad9d649ff58c147"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:23:46.536557Z",
     "start_time": "2024-11-13T09:23:46.496832Z"
    }
   },
   "cell_type": "code",
   "source": "from youtube_transcript_api import YouTubeTranscriptApi",
   "id": "983a534659406f8d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Grab the transcript of a YouTube video.",
   "id": "333dcfca01a425eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:23:49.129934Z",
     "start_time": "2024-11-13T09:23:47.826936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "video_id = 'EBpT_cscTis'\n",
    "transcript = YouTubeTranscriptApi.get_transcript(video_id)"
   ],
   "id": "c0e75dfee252204b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:23:49.137139Z",
     "start_time": "2024-11-13T09:23:49.131777Z"
    }
   },
   "cell_type": "code",
   "source": "transcript[:5]",
   "id": "e4b33cfb6a811b23",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'hey everyone Jerry here and in this',\n",
       "  'start': 0.76,\n",
       "  'duration': 4.039},\n",
       " {'text': \"video we're excited to feature weni who\",\n",
       "  'start': 2.679,\n",
       "  'duration': 4.961},\n",
       " {'text': 'will be talking about 12 rag pain points',\n",
       "  'start': 4.799,\n",
       "  'duration': 5.96},\n",
       " {'text': 'and proposed Solutions in llama index uh',\n",
       "  'start': 7.64,\n",
       "  'duration': 5.24},\n",
       " {'text': 'as a lot of people know uh who are',\n",
       "  'start': 10.759,\n",
       "  'duration': 4.321}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:23:53.389703Z",
     "start_time": "2024-11-13T09:23:53.386239Z"
    }
   },
   "cell_type": "code",
   "source": "full_transcript = ' '.join([line['text'] for line in transcript])",
   "id": "6a85499d5986f319",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:23:54.660363Z",
     "start_time": "2024-11-13T09:23:54.656513Z"
    }
   },
   "cell_type": "code",
   "source": "full_transcript[:100]",
   "id": "c4a9d98e921e3557",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hey everyone Jerry here and in this video we're excited to feature weni who will be talking about 12\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:23:55.847349Z",
     "start_time": "2024-11-13T09:23:55.844277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Rough word count in the full transcript\n",
    "len(full_transcript.split())"
   ],
   "id": "59f26276b087da76",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6606"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:23:56.931398Z",
     "start_time": "2024-11-13T09:23:56.927907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We are going to use Google Gemini because of the long context window. \n",
    "# Set up the environment variable GOOGLE_API_KEY.\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if os.environ.get(var):\n",
    "        return\n",
    "    os.environ[var] = getpass.getpass(var + \":\")"
   ],
   "id": "fd64f18f97a01610",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:24:00.281447Z",
     "start_time": "2024-11-13T09:23:58.238601Z"
    }
   },
   "cell_type": "code",
   "source": "_set_env(\"GOOGLE_API_KEY\")",
   "id": "1ec78fbdb6225576",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Summarize the video transcript using Gemini\n",
    "\n",
    "### Set up the prompts for the summarization."
   ],
   "id": "3657352d2c47c152"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:24:03.521330Z",
     "start_time": "2024-11-13T09:24:03.187477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "IDENTITY:\n",
    "You are a genius AI that helps people summarize YouTube videos. \n",
    "You have been trained on a large dataset of YouTube videos and their transcripts.\n",
    "\n",
    "INPUT: You receive the text transcript of a Youtube video.\n",
    "\n",
    "BEHAVIOUR:\n",
    "You examine the text transcript and extract the key information.\n",
    "You do not add your own information. \n",
    "You only summarize the information present in the text transcript.\n",
    "\n",
    "OUTPUT:\n",
    "The output should be well-formed Markdown.\n",
    "The output should have a target length of {word_count} words.\n",
    "The output should the following headings:\n",
    "- Video Title\n",
    "- Speakers in the video\n",
    "- Key points\n",
    "- Conclusions\n",
    "\"\"\"\n",
    "\n",
    "human_prompt = \"\"\"\n",
    "Video transcript:\n",
    "{transcript}\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", human_prompt),\n",
    "    ]\n",
    ")"
   ],
   "id": "88fd33c42936c884",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Set up the processing chain using LCEL",
   "id": "b98537b51066d2eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:24:59.363270Z",
     "start_time": "2024-11-13T09:24:57.966419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "long_context_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro-002\", temperature=1.0, max_output_tokens=8192)\n",
    "\n",
    "chain = prompt | long_context_llm | parser"
   ],
   "id": "48a7466ea87db9f1",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Invoke the chain to generate the summary",
   "id": "1a15309e344f7eae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:25:18.237614Z",
     "start_time": "2024-11-13T09:25:00.589322Z"
    }
   },
   "cell_type": "code",
   "source": "summary = chain.invoke(input={'transcript': full_transcript, 'word_count': 1000})",
   "id": "e77dfa5e5d2a12a2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:25:19.115787Z",
     "start_time": "2024-11-13T09:25:19.112372Z"
    }
   },
   "cell_type": "code",
   "source": "print(summary)",
   "id": "700edadbf133f5d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Video Title\n",
      "12 RAG Pain Points and Proposed Solutions in LlamaIndex\n",
      "\n",
      "# Speakers in the video\n",
      "- Jerry\n",
      "- Weni\n",
      "\n",
      "# Key Points\n",
      "\n",
      "Weni discusses 12 common pain points encountered when building Retrieval Augmented Generation (RAG) systems and proposes solutions using LlamaIndex. These pain points are categorized into response quality issues and additional complexities.\n",
      "\n",
      "**Response Quality Pain Points:**\n",
      "\n",
      "1. **Missing Content:** Hallucinations due to content missing in the knowledge base. Solutions include cleaning data using tools like UnstructuredIO and improving prompting.\n",
      "\n",
      "2. **Missed Top-Ranked Documents:** Missing crucial context during retrieval. Solutions involve hyperparameter tuning using LlamaIndex's Prompt Tuner with appropriate evaluators, and reranking retrieved nodes using techniques like CohereRanker.\n",
      "\n",
      "3. **Not In Context:** Context missing after ranking due to too many retrieved documents. Solutions include leveraging LlamaIndex's advanced retrieval strategies (e.g., hybrid retrievers, fusion, auto-merging) and fine-tuning embedding models.\n",
      "\n",
      "4. **Not Extracted:**  Context not extracted due to noise or contradicting information. Solutions include cleaning data, prompt compression techniques based on the LongLM Linga research, and utilizing node post-processors.\n",
      "\n",
      "5. **Long Context Reorder:** Addressing the \"lost in the middle\" problem with long contexts. Solutions include reordering nodes using node post-processors before feeding them to the language model.\n",
      "\n",
      "6. **Wrong Format:** Output not in the desired format. Solutions include better prompting, output parsing using LlamaIndex modules (e.g., structured output parsing, guardrails), and leveraging pre-packaged tools.  Using OpenAI's JSON mode is also suggested.\n",
      "\n",
      "7. **Incomplete Output:** Partial responses that are not entirely wrong but incomplete. Solutions involve using LlamaIndex's query transformations, including routing query engines, query rewriting, and sub-question query engines.\n",
      "\n",
      "**Additional Complexities:**\n",
      "\n",
      "8. **Data Ingestion Scalability:** Difficulty handling large datasets in enterprise settings. Solutions involve parallelizing the ingestion pipeline in LlamaIndex for faster processing.\n",
      "\n",
      "9. **Structured Data Q&A:** Challenges with text-to-SQL and inflexible querying. LlamaIndex offers solutions through LlamaPacks, integrating tools like \"Chain of Table\" and \"Mix Self-Consistency Pack\" for improved handling of tabular data.\n",
      "\n",
      "10. **Data Extraction from Complex PDFs:** Extracting data from PDFs with tables, images, and charts. LlamaIndex's LlamaPass and the \"Embed Tables and Structured Retriever Pack\" are recommended solutions, using tools like `pdfminer` for conversion to HTML.\n",
      "\n",
      "11. **Fallback Models:** Handling rate limits and model downtime.  LlamaIndex integrates with Neutrino Router and OpenRouter for automatic routing and fallback mechanisms to ensure service continuity.\n",
      "\n",
      "12. **LLM Security:** Ensuring responsible and safe LLM usage.  LlamaIndex supports Nemo Guardrails for comprehensive security features, including input/output moderation, topic guidance, and hallucination prevention.  Llama Moderator Pack is another option for basic content classification.\n",
      "\n",
      "# Conclusions\n",
      "\n",
      "Weni emphasizes the importance of these solutions in building robust and production-ready RAG applications. The LlamaIndex framework offers a rich set of tools and techniques to address various challenges encountered during development.  Further complexities like multi-tenancy are acknowledged, with existing solutions available in LlamaIndex using metadata.  The discussion highlights the need for continuous exploration and development in the RAG space to tackle evolving complexities and improve response quality.  Security aspects are emphasized as crucial considerations in LLM applications.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:25:56.145354Z",
     "start_time": "2024-11-13T09:25:56.143121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Write it out to a file to take a look at it in a Markdown editor.\n",
    "\n",
    "with open(f\"summary_{video_id}.md\", 'w') as f:\n",
    "    f.write(summary)"
   ],
   "id": "4761f77ed6dde6fb",
   "outputs": [],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
